{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Bookshelf Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robotic as ry\n",
    "import random\n",
    "import time\n",
    "speed = 0.1\n",
    "selected_color = [1, 0, 1]\n",
    "orig_color = [0.80, 0.80, 0.80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Add book_shelf.g and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vboxuser/Desktop/CS449/rai_venv/lib/python3.8/site-packages/robotic/rai-robotModels/\n"
     ]
    }
   ],
   "source": [
    "C = ry.Config()\n",
    "print(ry.raiPath(''))\n",
    "C.addFile(ry.raiPath('book_shelf.g'))\n",
    "\n",
    "C.view()\n",
    "qHome = C.getJointState()\n",
    "gripper_orig_pos = C.getFrame(\"l_gripper\").getPosition()\n",
    "gripper_orig_quat = C.getFrame(\"l_gripper\").getQuaternion()\n",
    "# print(C.getFrameNames())\n",
    "\n",
    "objects = [\"book1\", \"book2\", \"book3\", \"book4\", \"mug\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Randomly select an object + change color of selected obj (to pink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected object:  mug\n",
      "Object orientation:  vertical\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select an object randomly\n",
    "# curObj = random.choice(objects)\n",
    "\n",
    "curObj = \"mug\"\n",
    "\n",
    "print(\"Selected object: \", curObj)\n",
    "\n",
    "# color the selected object\n",
    "C.getFrame(curObj).setColor(selected_color)\n",
    "\n",
    "# determine orientation of object\n",
    "obj_z_height = C.getFrame(curObj).getSize()[2]\n",
    "obj_y_width = C.getFrame(curObj).getSize()[1]\n",
    "obj_x_length = C.getFrame(curObj).getSize()[0]\n",
    "\n",
    "if min(obj_z_height, obj_y_width, obj_x_length) == obj_z_height:\n",
    "  obj_orientation = \"horizontal\"\n",
    "elif min(obj_z_height, obj_y_width, obj_x_length) == obj_y_width:\n",
    "  obj_orientation = \"vertical\"\n",
    "elif min(obj_z_height, obj_y_width, obj_x_length) == obj_x_length:\n",
    "  obj_orientation = \"sideways\"\n",
    "  \n",
    "print(\"Object orientation: \", obj_orientation)\n",
    "\n",
    "\n",
    "komo = ry.KOMO()\n",
    "del komo\n",
    "C.setJointState(qHome)\n",
    "C.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Robot grasps object in a natural manner - uses the orientation of the object (calulcated in prev part) to determine how to grasp it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ time: 0.042918, evals: 23, done: 1, feasible: 0, sos: 56.79, f: 0, ineq: 0, eq: 3.12409 }\n"
     ]
    }
   ],
   "source": [
    "# komo = ry.KOMO(C, phases=1, slicesPerPhase=30, kOrder=1, enableCollisions=False)\n",
    "\n",
    "komo_1 = ry.KOMO()\n",
    "komo_1.setConfig(C, True)\n",
    "komo_1.setTiming(1., 10, 5., 0)\n",
    "\n",
    "# add collision constraints\n",
    "komo_1.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq, [1e0])\n",
    "komo_1.addObjective([], ry.FS.jointLimits, [], ry.OT.ineq)\n",
    "komo_1.addObjective([], ry.FS.jointState, [], ry.OT.sos, [1e0], qHome)\n",
    "\n",
    "# calculate gripper and cargo offset (-40% in x direction)\n",
    "offset_x = -(C.getFrame(curObj) .getSize()[0] * 0.45)\n",
    "# this objective moves the gripper close to the cargo\n",
    "komo_1.addObjective(\n",
    "    times=[],\n",
    "    feature=ry.FS.positionRel,\n",
    "    frames=['l_gripper', curObj],\n",
    "    type=ry.OT.eq,\n",
    "    scale=[1e1],\n",
    "    target=[offset_x, 0, 0]\n",
    ")\n",
    "# this objective makes the gripper claws face the shelf objects \n",
    "komo_1.addObjective(\n",
    "    times=[0, 1], \n",
    "    feature=ry.FS.scalarProductXZ, \n",
    "    frames=[curObj, 'l_gripper'], \n",
    "    type=ry.OT.eq, \n",
    "    scale=[1e1],\n",
    "    target=[-1]\n",
    ")\n",
    "\n",
    "\n",
    "# these 3 objectives align the gripper claws aligned properly with the book\n",
    "komo_1.addObjective(\n",
    "    times=[0, 1], \n",
    "    feature=ry.FS.scalarProductXX, \n",
    "    frames=['l_gripper', curObj], \n",
    "    type=ry.OT.eq, \n",
    "    scale=[1e1],\n",
    ")\n",
    "\n",
    "komo_1.addObjective(\n",
    "    times=[0, 1],\n",
    "    feature=ry.FS.scalarProductZZ, \n",
    "    frames=['l_gripper', curObj], \n",
    "    type=ry.OT.eq, \n",
    "    scale=[1e1]\n",
    ")\n",
    "\n",
    "komo_1.addObjective(\n",
    "    times=[0, 1],\n",
    "    feature=ry.FS.scalarProductYY, \n",
    "    frames=['l_gripper', curObj], \n",
    "    type=ry.OT.eq, \n",
    "    scale=[1e1]\n",
    ")\n",
    "\n",
    "# this objective makes the gripper claws vertical\n",
    "\n",
    "if obj_orientation == \"vertical\":\n",
    "    komo_1.addObjective(\n",
    "        times=[0, 1],\n",
    "        feature=ry.FS.scalarProductXY, \n",
    "        frames=['l_gripper', curObj], \n",
    "        type=ry.OT.eq, \n",
    "        scale=[1e1],\n",
    "        target=[1]\n",
    "    )\n",
    "elif obj_orientation == \"horizontal\":\n",
    "    komo_1.addObjective(\n",
    "        times=[0, 1],\n",
    "        feature=ry.FS.scalarProductXY, \n",
    "        frames=['l_gripper', curObj], \n",
    "        type=ry.OT.eq, \n",
    "        scale=[1e1],\n",
    "        target=[0]\n",
    "    )\n",
    "    # this objective re-adjusts the gripper claws' z and curObj's x to be parallel, to prevent angled grip(and thus no collision)\n",
    "    komo_1.addObjective(\n",
    "        times=[0, 1],\n",
    "        feature=ry.FS.scalarProductYY, \n",
    "        frames=['l_gripper', curObj], \n",
    "        type=ry.OT.eq, \n",
    "        scale=[1e2],\n",
    "        target=[1]\n",
    "    )\n",
    "\n",
    "# solve\n",
    "ret_1 = ry.NLP_Solver(komo_1.nlp(), verbose=0 ) .solve()\n",
    "print(ret_1)\n",
    "q_gripper_to_obj = komo_1.getPath()\n",
    "\n",
    "for t in range(q_gripper_to_obj.shape[0]):\n",
    "    C.setJointState(q_gripper_to_obj[t])\n",
    "    C.view(False, f'waypoint {t}')\n",
    "    time.sleep(speed)\n",
    "\n",
    "# komo_1.view_play(False, 2)\n",
    "\n",
    "# if ret_1.feasible:\n",
    "#     print(\"komo is feasible\")\n",
    "# else:\n",
    "#     print(\"komo is NOT feasible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Robot places object in goal area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ time: 0.025129, evals: 18, done: 1, feasible: 0, sos: 17.5871, f: 0, ineq: 0, eq: 7.173 }\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<robotic._robotic.Frame at 0x7fb5b193fd70>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.attach('l_gripper', curObj)\n",
    "komo_2 = ry.KOMO()\n",
    "komo_2.setConfig(C, True)\n",
    "komo_2.setTiming(1., 10, 5., 0)\n",
    "\n",
    "# add collision constraints\n",
    "komo_2.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq, [1e0])\n",
    "komo_2.addObjective([], ry.FS.jointLimits, [], ry.OT.ineq)\n",
    "komo_2.addObjective([], ry.FS.jointState, [], ry.OT.sos, [1e0], qHome)\n",
    "\n",
    "# calculate gripper and goal offset (in z direction)\n",
    "curObjPos = C.getFrame(curObj).getSize()\n",
    "if max(curObjPos) == curObjPos[0]:\n",
    "    goal_offset = [curObjPos[0], 0, 0]\n",
    "elif max(curObjPos) == curObjPos[1]:\n",
    "    goal_offset = [0, curObjPos[1], 0]\n",
    "else:\n",
    "    goal_offset = [0, 0, curObjPos[2]]\n",
    "\n",
    "\n",
    "# this objective moves the gripper close to the goal\n",
    "komo_2.addObjective(\n",
    "    times=[],\n",
    "    feature=ry.FS.positionRel,\n",
    "    frames=['l_gripper', 'goal'],\n",
    "    type=ry.OT.eq,\n",
    "    scale=[1e1],\n",
    "    target=goal_offset\n",
    ")\n",
    "\n",
    "komo_2.addObjective(\n",
    "    times=[],\n",
    "    feature=ry.FS.positionDiff,\n",
    "    frames=[curObj, 'goal'],\n",
    "    type=ry.OT.eq,\n",
    "    scale=[1e1],\n",
    "    target=[0, 0, 0.025]\n",
    ")\n",
    "\n",
    "komo_2.addObjective(\n",
    "    times=[],\n",
    "    feature=ry.FS.scalarProductXZ,\n",
    "    frames=['l_gripper', \"goal\"],\n",
    "    type=ry.OT.eq,\n",
    "    scale=[1e1],\n",
    "    target=[0]\n",
    ")\n",
    "\n",
    "komo_2.addObjective(\n",
    "    times=[],\n",
    "    feature=ry.FS.scalarProductYZ,\n",
    "    frames=['goal', 'l_gripper'],\n",
    "    type=ry.OT.eq,\n",
    "    scale=[1e1],\n",
    "    target=[0]\n",
    ")\n",
    "\n",
    "\n",
    "# solve\n",
    "ret_2 = ry.NLP_Solver(komo_2.nlp(), verbose=0 ) .solve()\n",
    "print(ret_2)\n",
    "q_obj_to_goal = komo_2.getPath()\n",
    "\n",
    "for t in range(q_obj_to_goal.shape[0]):\n",
    "    C.setJointState(q_obj_to_goal[t])\n",
    "    C.view(False, f'waypoint {t}')\n",
    "    time.sleep(speed)\n",
    "    \n",
    "C.getFrame(curObj) .unLink() .setColor(orig_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Robot returns to home position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.setJointState(qHome)\n",
    "C.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc functions (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset colors\n",
    "for obj in objects:\n",
    "    C.getFrame(obj).setColor(orig_color)\n",
    "C.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C.addFrame(\"visual\") .setPosition(C.getFrame(\"goal\").getPosition()) .setColor([0, 1, 1]) .setShape(ry.ST.marker, [0.7])\n",
    "# # # C.addFrame(\"visual_gripper_orig\")  .setShape(ry.ST.marker, [0.]).setPosition(gripper_orig_pos) .setQuaternion(gripper_orig_quat) .setColor([0, 1, 0])\n",
    "# C.addFrame(\"visual_gripper_final\") .setShape(ry.ST.marker, [0.4]) .setPosition(C.getFrame(\"l_gripper\").getPosition()) .setQuaternion(C.getFrame(\"l_gripper\").getQuaternion()) .setColor([0, 1, 0]) \n",
    "# C.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reinitialise komo and arm position\n",
    "# try:\n",
    "#     del komo_2\n",
    "# except:\n",
    "#     pass\n",
    "# C.setJointState(q_gripper_to_obj[0])\n",
    "# C.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
