{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "/home/vboxuser/Desktop/CS449/rai_venv/lib/python3.8/site-packages/robotic/rai-robotModels/environment.g\n"
     ]
    }
   ],
   "source": [
    "import robotic as ry\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import time\n",
    "\n",
    "pclColor = [0,0,255]\n",
    "max_trials = 10\n",
    "max_vel = 100\n",
    "max_acc = max_vel\n",
    "\n",
    "C = ry.Config()\n",
    "C.addFile('/home/vboxuser/Desktop/CS449/Migi/hw3/GFiles-HW3/environment.g')\n",
    "\n",
    "# C.addFile('./environment.g')\n",
    "# C.addFile(ry.raiPath('environment.g'))\n",
    "# qHome = C.getJointState()\n",
    "# print(qHome)\n",
    "C.view()\n",
    "print(ry.raiPath('environment.g'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Perception Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get point clouds for each camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640, 3)\n",
      "(360, 640, 3)\n",
      "(360, 640, 3)\n",
      "(360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "numOfCameras = 4\n",
    "cam = [None] * numOfCameras\n",
    "rgb = [None] * numOfCameras\n",
    "depth = [None] * numOfCameras\n",
    "pcl = [None] * numOfCameras\n",
    "\n",
    "\n",
    "for i in range(numOfCameras):\n",
    "  cam[i] = ry.CameraView(C)\n",
    "  cam[i].setCamera('camera'+str(i+1))\n",
    "  rgb[i], depth[i] = cam[i].computeImageAndDepth(C)\n",
    "  pcl[i] = ry.depthImage2PointCloud(depth[i], cam[i].getFxycxy())\n",
    "  print(pcl[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now normalise the points relative to world frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(numOfCameras):\n",
    "  curCam = C.getFrame(\"camera\"+str(i+1))  \n",
    "  curCamRotMat = curCam.getRotationMatrix()\n",
    "  curCamPos = curCam.getPosition()\n",
    "    \n",
    "  for h in range(pcl[i].shape[0]):    # Iterate over height\n",
    "    for w in range(pcl[i].shape[1]):  # Iterate over width\n",
    "      point = pcl[i][h, w]            # Get the 3D point [x, y, z]\n",
    "     \n",
    "      # Apply rotation\n",
    "      rotated_point = np.dot(curCamRotMat, point)  # Rotate the point\n",
    "      \n",
    "      # Apply translation\n",
    "      transformed_point = rotated_point + curCamPos  # Add the camera position\n",
    "      \n",
    "      pcl[i][h, w] = transformed_point      \n",
    "      \n",
    "\n",
    "# # Visualize the point cloud\n",
    "# pclFrames = [None] * numOfCameras\n",
    "\n",
    "# for i in range(numOfCameras):\n",
    "#   pclFrames[i] = C.addFrame('pcl'+str(i+1), 'world')\n",
    "#   pclFrames[i].setPointCloud(pcl[i], pclColor)\n",
    "# C.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we extract the ones inside the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "centre = C.getFrame(\"bin\").getPosition()\n",
    "centre[2] = centre[2] + 0.083  # Raise slightly to remove bin surface\n",
    "\n",
    "off = .1\n",
    "offsets = [0.3, 0.25, 0.05]\n",
    "\n",
    "bounding_box_min_x = centre[0] - offsets[0]\n",
    "bounding_box_max_x = centre[0] + offsets[0]\n",
    "\n",
    "bounding_box_min_y = centre[1] - offsets[1]\n",
    "bounding_box_max_y = centre[1] + offsets[1]\n",
    "\n",
    "bounding_box_min_z = centre[2] - offsets[2]\n",
    "bounding_box_max_z = centre[2] + offsets[2]\n",
    "\n",
    "\n",
    "for i in range(numOfCameras):\n",
    "  for h in range(pcl[i].shape[0]):  \n",
    "    for w in range(pcl[i].shape[1]):  \n",
    "      point = pcl[i][h, w] \n",
    "      eachX, eachY, eachZ = point  \n",
    "      \n",
    "      # Check if the point is within the bounding box\n",
    "      if not (bounding_box_min_x < eachX < bounding_box_max_x and\n",
    "              bounding_box_min_y < eachY < bounding_box_max_y and\n",
    "              bounding_box_min_z < eachZ < bounding_box_max_z):\n",
    "          pcl[i][h, w] = [0, 0, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now combine pcl from the 4 cameras and view the final bounded point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pclFrames = [None] * numOfCameras\n",
    "\n",
    "pclCombined = np.concatenate(pcl, axis=0)\n",
    "pclFrame = C.addFrame('pcl', 'world')\n",
    "pclFrame.setPointCloud(pclCombined, pclColor)\n",
    "  \n",
    "C.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we do the normals usoing open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to a 2D array\n",
    "pclCombined_reshaped = pclCombined.reshape(-1, 3)  # Collapse the first two dimensions into one\n",
    "\n",
    "print(pclCombined_reshaped.shape)  # Should now be (1440 * 640, 3)\n",
    "\n",
    "# Convert to Open3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pclCombined_reshaped)\n",
    "\n",
    "# Visualize the point cloud\n",
    "# o3d.visualization.draw_geometries([pcd])\n",
    "print(\"Downsample the point cloud with a voxel of 0.05\")\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.005)\n",
    "downpcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "o3d.visualization.draw_geometries([downpcd])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
