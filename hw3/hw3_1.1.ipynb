{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vboxuser/Desktop/CS449/rai_venv/lib/python3.8/site-packages/robotic/rai-robotModels/environment.g\n"
     ]
    }
   ],
   "source": [
    "import robotic as ry\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pclColor = [0,0,255]\n",
    "max_trials = 10\n",
    "max_vel = 100\n",
    "max_acc = max_vel\n",
    "\n",
    "C = ry.Config()\n",
    "C.addFile('/home/vboxuser/Desktop/CS449/Migi/hw3/GFiles-HW3/environment.g')\n",
    "\n",
    "# C.addFile('./environment.g')\n",
    "# C.addFile(ry.raiPath('environment.g'))\n",
    "# qHome = C.getJointState()\n",
    "# print(qHome)\n",
    "C.view()\n",
    "print(ry.raiPath('environment.g'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Perception Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get point clouds for each camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640, 3)\n",
      "(360, 640, 3)\n",
      "(360, 640, 3)\n",
      "(360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "numOfCameras = 4\n",
    "cam = [None] * numOfCameras\n",
    "rgb = [None] * numOfCameras\n",
    "depth = [None] * numOfCameras\n",
    "pcl = [None] * numOfCameras\n",
    "\n",
    "\n",
    "for i in range(numOfCameras):\n",
    "  cam[i] = ry.CameraView(C)\n",
    "  cam[i].setCamera('camera'+str(i+1))\n",
    "  rgb[i], depth[i] = cam[i].computeImageAndDepth(C)\n",
    "  pcl[i] = ry.depthImage2PointCloud(depth[i], cam[i].getFxycxy())\n",
    "  print(pcl[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now normalise the points relative to world frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(numOfCameras):\n",
    "  curCam = C.getFrame(\"camera\"+str(i+1))  \n",
    "  curCamRotMat = curCam.getRotationMatrix()\n",
    "  curCamPos = curCam.getPosition()\n",
    "    \n",
    "  for h in range(pcl[i].shape[0]):    # Iterate over height\n",
    "    for w in range(pcl[i].shape[1]):  # Iterate over width\n",
    "      point = pcl[i][h, w]            # Get the 3D point [x, y, z]\n",
    "     \n",
    "      # Apply rotation\n",
    "      rotated_point = np.dot(curCamRotMat, point)  # Rotate the point\n",
    "      \n",
    "      # Apply translation\n",
    "      transformed_point = rotated_point + curCamPos  # Add the camera position\n",
    "      \n",
    "      pcl[i][h, w] = transformed_point      \n",
    "      \n",
    "\n",
    "# # Visualize the point cloud\n",
    "# pclFrames = [None] * numOfCameras\n",
    "\n",
    "# for i in range(numOfCameras):\n",
    "#   pclFrames[i] = C.addFrame('pcl'+str(i+1), 'world')\n",
    "#   pclFrames[i].setPointCloud(pcl[i], pclColor)\n",
    "# C.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we extract the ones inside the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "centre = C.getFrame(\"bin\").getPosition()\n",
    "centre[2] = centre[2] + 0.087  # Raise slightly to remove bin surface\n",
    "\n",
    "off = .1\n",
    "offsets = [0.3, 0.25, 0.05]\n",
    "\n",
    "bounding_box_min_x = centre[0] - offsets[0]\n",
    "bounding_box_max_x = centre[0] + offsets[0]\n",
    "\n",
    "bounding_box_min_y = centre[1] - offsets[1]\n",
    "bounding_box_max_y = centre[1] + offsets[1]\n",
    "\n",
    "bounding_box_min_z = centre[2] - offsets[2]\n",
    "bounding_box_max_z = centre[2] + offsets[2]\n",
    "\n",
    "\n",
    "for i in range(numOfCameras):\n",
    "  for h in range(pcl[i].shape[0]):  \n",
    "    for w in range(pcl[i].shape[1]):  \n",
    "      point = pcl[i][h, w] \n",
    "      eachX, eachY, eachZ = point  \n",
    "      \n",
    "      # Check if the point is within the bounding box\n",
    "      if not (bounding_box_min_x < eachX < bounding_box_max_x and\n",
    "              bounding_box_min_y < eachY < bounding_box_max_y and\n",
    "              bounding_box_min_z < eachZ < bounding_box_max_z):\n",
    "          pcl[i][h, w] = [0, 0, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now combine pcl from the 4 cameras and view the final bounded point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pclFrames = [None] * numOfCameras\n",
    "\n",
    "pclCombined = np.concatenate(pcl, axis=0)\n",
    "pclFrame = C.addFrame('pcl', 'world')\n",
    "pclFrame.setPointCloud(pclCombined, pclColor)\n",
    "  \n",
    "C.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Prediction Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxelSize = 0.008\n",
    "numOfObjects = 3\n",
    "degToleration = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we do the normals usoing open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(921600, 3)\n",
      "Downsample the point cloud with a voxel of 0.05\n"
     ]
    }
   ],
   "source": [
    "# Reshape to a 2D array\n",
    "pclCombined_reshaped = pclCombined.reshape(-1, 3)  # Collapse the first two dimensions into one\n",
    "\n",
    "print(pclCombined_reshaped.shape)  # Should now be (1440 * 640, 3)\n",
    "\n",
    "# Convert to Open3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(pclCombined_reshaped)\n",
    "\n",
    "# #  Visualize the point cloud\n",
    "# o3d.visualization.draw_geometries([pcd])\n",
    "print(\"Downsample the point cloud with a voxel of 0.05\")\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=voxelSize)\n",
    "downpcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "# o3d.visualization.draw_geometries([downpcd], normals=True)\n",
    "\n",
    "# # print list of normals\n",
    "# normals = np.asarray(downpcd.normals)\n",
    "# print(normals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we do the clustering using kmeans from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vboxuser/Desktop/CS449/rai_venv/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 1 1]\n",
      "Normals are already estimated.\n",
      "Normal magnitudes (first 10): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Are normals normalized?  True\n"
     ]
    }
   ],
   "source": [
    "# Cluster using kmeans from sklearn, there are 3 objects in the point cloud so we will use 3 clusters\n",
    "kmeans = KMeans(n_clusters=numOfObjects, random_state=0).fit(np.asarray(downpcd.points))\n",
    "print(kmeans.labels_)\n",
    "\n",
    "# Visualize the clusters\n",
    "clusters = []\n",
    "for i in range(numOfObjects):\n",
    "  cluster = downpcd.select_by_index(np.where(kmeans.labels_ == i)[0])\n",
    "  cluster.paint_uniform_color([(i == 0), (i == 1), (i == 2)])\n",
    "  clusters.append(cluster)\n",
    "  \n",
    "# Check if normals are estimated\n",
    "if downpcd.has_normals():\n",
    "    print(\"Normals are already estimated.\")\n",
    "else:\n",
    "    print(\"Normals are not estimated yet. Estimating now...\")\n",
    "    downpcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "    print(\"Normals estimated.\")\n",
    "\n",
    "# Verify magnitudes of normals\n",
    "normals = np.asarray(downpcd.normals)\n",
    "magnitudes = np.linalg.norm(normals, axis=1)\n",
    "print(\"Normal magnitudes (first 10):\", magnitudes[:10])\n",
    "print(\"Are normals normalized? \", np.allclose(magnitudes, 1.0, atol=1e-6))\n",
    "\n",
    "# # Visualize point cloud with normals\n",
    "# print(\"Visualizing the point cloud with normals...\")\n",
    "# o3d.visualization.draw_geometries([downpcd], point_show_normal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing normals for Cluster 1...\n",
      "Reorienting normals...\n",
      "Fixing normals for Cluster 2...\n",
      "Reorienting normals...\n",
      "Fixing normals for Cluster 3...\n",
      "Reorienting normals...\n"
     ]
    }
   ],
   "source": [
    "# Fix normals orientation by aligning them towards a camera position\n",
    "def reorient_normals(cluster):\n",
    "    print(\"Reorienting normals...\")\n",
    "    viewpoint = np.array([0, 0, 0])  # Replace with the actual camera or world origin\n",
    "    cluster.orient_normals_towards_camera_location(camera_location=viewpoint)\n",
    "\n",
    "# Reorient normals for each cluster\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"Fixing normals for Cluster {i+1}...\")\n",
    "    reorient_normals(cluster)\n",
    "\n",
    "# # Visualize the corrected normals\n",
    "# for i, cluster in enumerate(clusters):\n",
    "#     print(f\"Visualizing corrected normals for Cluster {i+1}...\")\n",
    "#     o3d.visualization.draw_geometries([cluster], point_show_normal=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we find antipodal grasp points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cluster 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4495/1478565827.py:14: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.arccos(dot_product)  # Angle in radians\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of potential grasp pairs in Cluster 1: 77\n",
      "Visualizing grasp pairs for Cluster 1...\n",
      "Visualizing grasp pairs...\n",
      "Processing Cluster 2...\n",
      "Number of potential grasp pairs in Cluster 2: 402\n",
      "Visualizing grasp pairs for Cluster 2...\n",
      "Visualizing grasp pairs...\n",
      "Processing Cluster 3...\n",
      "Number of potential grasp pairs in Cluster 3: 194\n",
      "Visualizing grasp pairs for Cluster 3...\n",
      "Visualizing grasp pairs...\n"
     ]
    }
   ],
   "source": [
    "def find_antipodal_grasp_points(cluster):\n",
    "    points = np.asarray(cluster.points)\n",
    "    normals = np.asarray(cluster.normals)\n",
    "    \n",
    "    grasp_pairs = []\n",
    "    \n",
    "    # Iterate through all point pairs\n",
    "    for i in range(len(points)):\n",
    "        for j in range(i + 1, len(points)):\n",
    "            # Compute the angle between normals\n",
    "            normal_i = normals[i]\n",
    "            normal_j = normals[j]\n",
    "            dot_product = np.dot(normal_i, normal_j)\n",
    "            angle = np.arccos(dot_product)  # Angle in radians\n",
    "            \n",
    "            # Check if angle is close to 180 degrees (antipodal condition)\n",
    "            if np.abs(np.degrees(angle) - 180) < degToleration:  # 10-degree tolerance\n",
    "                grasp_pairs.append((i, j))\n",
    "    \n",
    "    return grasp_pairs\n",
    "\n",
    "def visualize_grasp_pairs(cluster, grasp_pairs):\n",
    "    import open3d as o3d\n",
    "\n",
    "    points = np.asarray(cluster.points)\n",
    "    lines = []\n",
    "    line_colors = []\n",
    "\n",
    "    # Create lines connecting grasp pairs\n",
    "    for pair in grasp_pairs:\n",
    "        idx1, idx2 = pair\n",
    "        lines.append([idx1, idx2])\n",
    "        line_colors.append([1, 0, 0])  # Red lines for grasp pairs\n",
    "\n",
    "    # Create Open3D line set for visualization\n",
    "    line_set = o3d.geometry.LineSet()\n",
    "    line_set.points = o3d.utility.Vector3dVector(points)\n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "    line_set.colors = o3d.utility.Vector3dVector(line_colors)\n",
    "\n",
    "    # Visualize\n",
    "    print(\"Visualizing grasp pairs...\")\n",
    "    o3d.visualization.draw_geometries([cluster, line_set])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Process each cluster\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"Processing Cluster {i+1}...\")\n",
    "    \n",
    "    grasp_points = find_antipodal_grasp_points(cluster)\n",
    "    print(f\"Number of potential grasp pairs in Cluster {i+1}: {len(grasp_points)}\")\n",
    "    \n",
    "    print(f\"Visualizing grasp pairs for Cluster {i+1}...\")\n",
    "    visualize_grasp_pairs(cluster, grasp_points)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
